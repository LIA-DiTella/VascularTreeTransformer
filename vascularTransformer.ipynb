{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from generateTrees import generate_random_tree, serialize, deserialize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
    "        super(DecoderOnlyTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.decoder_layers = nn.TransformerDecoderLayer(d_model, nhead)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x\", x)\n",
    "        #print(\"shape x\", x.shape)\n",
    "        x = self.embedding(x)\n",
    "        #print(\"embedding\", x.shape)\n",
    "        memory = torch.zeros_like(x)\n",
    "        output = self.transformer_decoder(x, memory)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, start_token, stop_token, max_length=10):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        current_token = torch.tensor([start_token])\n",
    "\n",
    "        generated_sequence = [start_token]\n",
    "\n",
    "        # Generate sequences until the stop token is encountered or reach max length\n",
    "        for _ in range(max_length):\n",
    "            logits = model(current_token.unsqueeze(0))  # Add batch dimension\n",
    "            \n",
    "\n",
    "            # Sample the next token using argmax\n",
    "            next_token = torch.argmax(logits[:, -1, :]).item()\n",
    "            # Append the next token to the generated sequence\n",
    "            generated_sequence.append(next_token)\n",
    "\n",
    "            # If the stop token is encountered, break the loop\n",
    "            if next_token == stop_token:\n",
    "                break\n",
    "\n",
    "            # Update the current token for the next iteration\n",
    "            current_token = torch.tensor([next_token])\n",
    "\n",
    "        return generated_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree(filename, dir):\n",
    "    with open(dir +'/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file, dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.data[idx]\n",
    "        tree = tree.split(';')\n",
    "        tree = [int(item) for item in tree]\n",
    "        tree = torch.tensor(tree)\n",
    "        return tree\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 4.733096599578857\n",
      "Epoch [6/500], Loss: 1.6829800605773926\n",
      "Epoch [11/500], Loss: 1.1884506940841675\n",
      "Epoch [16/500], Loss: 1.057334542274475\n",
      "Epoch [21/500], Loss: 1.0292863845825195\n",
      "Epoch [26/500], Loss: 1.1998032331466675\n",
      "Epoch [31/500], Loss: 1.1205837726593018\n",
      "Epoch [36/500], Loss: 1.1901538372039795\n",
      "Epoch [41/500], Loss: 1.4190853834152222\n",
      "Epoch [46/500], Loss: 1.0904301404953003\n",
      "Epoch [51/500], Loss: 1.1351103782653809\n",
      "Epoch [56/500], Loss: 1.1282031536102295\n",
      "Epoch [61/500], Loss: 1.2178326845169067\n",
      "Epoch [66/500], Loss: 1.3601503372192383\n",
      "Epoch [71/500], Loss: 1.091884732246399\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m target_sequence \u001b[38;5;241m=\u001b[39m [lst[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m lst \u001b[38;5;129;01min\u001b[39;00m padded_batch]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m##padding para que las secuencias tengan el mismo largo\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mfor i in range(batch_size):\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    predicted_tokens = torch.argmax(outputs[i], dim=-1).tolist()\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    print(f\"Batch {batch_idx + 1}, Sequence {i + 1} - Predicted tokens: {predicted_tokens}\")\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    for j in range(len(predicted_tokens)):\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m        print(\"token en la sequencia original - token que predijo\", target_sequence[i][j].item(), predicted_tokens[j])'''\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Calculate the loss using the shifted target sequence\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 15\u001b[0m, in \u001b[0;36mDecoderOnlyTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#print(\"embedding\", x.shape)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(x)\n\u001b[1;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:460\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    457\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 460\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:847\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[1;32m--> 847\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    848\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:865\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mha_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[0;32m    864\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 865\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torch\\lib\\site-packages\\torch\\nn\\functional.py:5443\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[0;32m   5441\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m-> 5443\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5444\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[0;32m   5446\u001b[0m     \u001b[38;5;66;03m# squeeze the output if input was unbatched\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = 100\n",
    "model = DecoderOnlyTransformer(vocab_size=vocab_size, d_model=256, nhead=4, num_layers=3)\n",
    "\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "num_epochs = 500\n",
    "losses = []\n",
    "\n",
    "folder = \"trees\"\n",
    "t_list = os.listdir( folder)[:1]\n",
    "dataset = tDataset(t_list, folder )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "# Count the occurrences of each class\n",
    "input = next(iter(data_loader))[0].tolist()\n",
    "vocab_classes = set(range(vocab_size))\n",
    "#print(\"input\", input)\n",
    "class_counts = dict(zip(*np.unique(input, return_counts=True)))\n",
    "# Add missing classes from the vocabulary with zero occurrences\n",
    "vocab_classes = set(range(vocab_size))\n",
    "for cls in vocab_classes - set(class_counts.keys()):\n",
    "    class_counts[cls] = 0\n",
    "\n",
    "ordered_counts = dict(sorted(class_counts.items()))\n",
    "total_samples = len(input)\n",
    "class_frequencies = {cls: 1 / count if count != 0 else 0 for cls, count in ordered_counts.items()}\n",
    "\n",
    "\n",
    "class_weights_tensor = torch.tensor([class_frequencies[cls] for cls in range(len(class_frequencies))], dtype=torch.float32)\n",
    "mult = torch.tensor([1/round(5),1/round(2),1/round(3)])\n",
    "\n",
    "#print(\"weights\", class_weights_tensor)\n",
    "#print(\"mult\", mult)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_batch = []\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        #print(\"batch\", batch)\n",
    "        optimizer.zero_grad()\n",
    "        max_seq_length = max(len(seq) for seq in batch)\n",
    "        padded_batch = [torch.nn.functional.pad(seq, pad=(0, max_seq_length - len(seq))) for seq in batch]\n",
    "        input_sequence = [lst[:-1] for lst in padded_batch]\n",
    "        target_sequence = [lst[1:] for lst in padded_batch]\n",
    "\n",
    "        # Forward pass\n",
    "        ##padding para que las secuencias tengan el mismo largo\n",
    "        outputs = model(torch.stack(input_sequence))\n",
    "        '''\n",
    "        for i in range(batch_size):\n",
    "            predicted_tokens = torch.argmax(outputs[i], dim=-1).tolist()\n",
    "            print(f\"Batch {batch_idx + 1}, Sequence {i + 1} - Predicted tokens: {predicted_tokens}\")\n",
    "            for j in range(len(predicted_tokens)):\n",
    "                print(\"token en la sequencia original - token que predijo\", target_sequence[i][j].item(), predicted_tokens[j])'''\n",
    "\n",
    "        # Calculate the loss using the shifted target sequence\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), torch.cat(target_sequence))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_batch.append(loss.item())\n",
    "    losses.append(np.average(loss_batch))\n",
    "    if (epoch) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {np.average(loss_batch)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence:\n",
      "[85, 97, 99, 34, 39, 99, 34, 39, 99, 34, 39]\n"
     ]
    }
   ],
   "source": [
    "# Plotting the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Choose a starting token and stop token for generation\n",
    "start_token = torch.randint(0, vocab_size, (1,))\n",
    "stop_token = torch.randint(0, vocab_size, (1,))\n",
    "\n",
    "# Generate a sequence using autoregressive sampling\n",
    "generated_sequence = generate_sequence(model, start_token.item(), stop_token.item(), max_length=10)\n",
    "\n",
    "\n",
    "# Print the generated sequence\n",
    "print(\"Generated Sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "99;99;39;99;99;22;7;99;99;39;99;99;26;41;98;99;99;43;99;99;34;39;99;99;62;30;97"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
